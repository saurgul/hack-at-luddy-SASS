{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hack-at-Luddy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team SASS - Final IPYNB File"
      ],
      "metadata": {
        "id": "k9K4sVWoOcmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to presentation and files - https://drive.google.com/drive/folders/1m8FXm0XZ-6hF2uosKARgbTXmq0EiNNty"
      ],
      "metadata": {
        "id": "_kq-V80nOaqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6CYrfHFr3RrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2918c5-3c02-4c1f-c569-b2a0a15de883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contextualSpellCheck in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from contextualSpellCheck) (3.2.3)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from contextualSpellCheck) (4.17.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from contextualSpellCheck) (1.10.0+cu111)\n",
            "Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from contextualSpellCheck) (0.5.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (1.21.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (0.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (1.8.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (0.9.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (2.4.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (8.0.13)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (3.10.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->contextualSpellCheck) (0.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->contextualSpellCheck) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->contextualSpellCheck) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->contextualSpellCheck) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (3.0.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (0.0.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (0.11.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (4.11.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->contextualSpellCheck) (0.4.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->contextualSpellCheck) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->contextualSpellCheck) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->contextualSpellCheck) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->contextualSpellCheck) (1.1.0)\n",
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n",
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install contextualSpellCheck\n",
        "import contextualSpellCheck\n",
        "\n",
        "import string\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download()\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = '/drive/My Drive/Colab Notebooks/Hack-at-Luddy/'\n",
        "\n",
        "train_df = pd.read_csv(filePath+'train_dataset.csv', encoding = \"ISO-8859-1\")\n",
        "test_df = pd.read_csv(filePath+'test_dataset.csv', encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "jHaqHs203X0W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Target'] = np.nan"
      ],
      "metadata": {
        "id": "feNYUBtMKUG2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWh6NMzZ5Vih",
        "outputId": "09d99165-d164-427a-d1bf-3d010a88246e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'key', 'ID', 'create_date', 'user',\n",
              "       'userID', 'RT_TF', 'full_text', 'Sample.ID.x', 'Sample.ID.y',\n",
              "       'Still.Exists.x', 'Still.Exists.y', 'In.English.x', 'In.English.y',\n",
              "       'Sarcasm.x', 'Sarcasm.y', 'Additional.Comments.x',\n",
              "       'Additional.Comments.y', 'User.x', 'User.y', 'Antisemitism.Rating.x',\n",
              "       'Antisemitism.Rating.y', 'Disagree.With.x', 'Disagree.With.y',\n",
              "       'Sentiment.Rating.x', 'Sentiment.Rating.y', 'Calling.Out.x',\n",
              "       'Calling.Out.y', 'Is.About.the.Holocaust.x', 'Is.About.the.Holocaust.y',\n",
              "       'IHRA.Section.x', 'IHRA.Section.y', 'sample_name',\n",
              "       'Is.About.The.Holocaust.x', 'Is.About.The.Holocaust.y', 'Target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Is.About.the.Holocaust.x'] = train_df['Is.About.the.Holocaust.x'].replace(np.nan,0)\n",
        "train_df['Is.About.the.Holocaust.y'] = train_df['Is.About.the.Holocaust.y'].replace(np.nan,0)\n",
        "\n",
        "train_df['Is.About.The.Holocaust.x'] = train_df['Is.About.The.Holocaust.x'].replace(np.nan,0)\n",
        "train_df['Is.About.The.Holocaust.y'] = train_df['Is.About.The.Holocaust.y'].replace(np.nan,0)\n"
      ],
      "metadata": {
        "id": "Qrl9JMdl9QE5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Is.About.the.Holocaust.x'] = train_df[[\"Is.About.the.Holocaust.x\", \"Is.About.The.Holocaust.x\"]].max(axis=1)\n",
        "train_df['Is.About.the.Holocaust.y'] = train_df[[\"Is.About.the.Holocaust.y\", \"Is.About.The.Holocaust.y\"]].max(axis=1)\n"
      ],
      "metadata": {
        "id": "LyHPIH4s_Q3J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop('Is.About.The.Holocaust.x', axis = 1)\n",
        "train_df = train_df.drop('Is.About.The.Holocaust.y', axis = 1)\n",
        "train_df = train_df.drop('Unnamed: 0.1', axis = 1)\n",
        "train_df = train_df.drop('Unnamed: 0', axis = 1)"
      ],
      "metadata": {
        "id": "mCnaR4KY_5Q8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[['Target','Sentiment.Rating.x']].corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "6us6eXnJAhZx",
        "outputId": "d87e9f27-c046-4f7c-e83f-9d43ce21d250"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a5934c0-1281-4bee-8a03-e114b031fca3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Sentiment.Rating.x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.58991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment.Rating.x</th>\n",
              "      <td>-0.58991</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a5934c0-1281-4bee-8a03-e114b031fca3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a5934c0-1281-4bee-8a03-e114b031fca3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a5934c0-1281-4bee-8a03-e114b031fca3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     Target  Sentiment.Rating.x\n",
              "Target              1.00000            -0.58991\n",
              "Sentiment.Rating.x -0.58991             1.00000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df = train_df[['full_text','Target']]\n",
        "testing_df = test_df[['full_text','Target']]\n",
        "print(training_df.shape)\n",
        "print(testing_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlUsHdg4FklI",
        "outputId": "2f317816-f9db-4734-c07f-ca7f4079a662"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3216, 2)\n",
            "(804, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF, testDF = train_test_split(training_df, test_size = 0.2)\n",
        "testDF, validDF = train_test_split(testDF, test_size = 0.2)"
      ],
      "metadata": {
        "id": "T0GxUVO4HpRe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainDF.shape)\n",
        "print(testDF.shape)\n",
        "print(validDF.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57m113CRH_yE",
        "outputId": "9d2d27b8-f2a2-46a1-9482-db2c0b045b8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2572, 2)\n",
            "(515, 2)\n",
            "(129, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data= pd.concat([training_df,testing_df],axis=0,ignore_index=True)"
      ],
      "metadata": {
        "id": "aiFe0IrlICtv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "    url=re.compile(r'https?://S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "def remove_html(text):\n",
        "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "    return re.sub(html, '', text)"
      ],
      "metadata": {
        "id": "i6VgnKi2IWdt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['full_text']=total_data['full_text'].apply(lambda x:remove_url(x))\n",
        "total_data['full_text']=total_data['full_text'].apply(lambda x:remove_html(x))"
      ],
      "metadata": {
        "id": "RKv-bBPTIhIS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(total_data)):\n",
        "    total_data['full_text'][i].lower()"
      ],
      "metadata": {
        "id": "MEKft69hKe86"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izAyP0B-Knon",
        "outputId": "c8f788fa-b081-4032-f798-8b5c09995cb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mustn', 'am', 'for', 'some', 'off', 'hadn', 'will', 'hasn', 'and', \"that'll\", 'isn', 'himself', 'had', 'nor', 'weren', 'own', 'whom', 'o', \"haven't\", 'of', \"needn't\", \"you'd\", 'until', 'them', 'ma', 'mightn', 'on', 'my', 'yourself', 'by', 'those', 'below', 'her', 'a', 'no', 'ourselves', 'down', 'doesn', 'then', 'that', 'an', 'while', 'as', 'few', \"isn't\", \"wasn't\", 'very', 'too', \"you're\", 'more', 'yourselves', 'each', 'herself', 'over', 'with', 'further', 'theirs', 'any', 'where', 'i', 'through', 'when', 'don', 'against', 'to', 'you', 'how', 'once', 'not', 've', \"hasn't\", 'it', \"weren't\", 'out', \"don't\", 'both', 'm', 'll', 'now', 'our', 'just', 'didn', \"she's\", 'again', 'he', 'into', \"hadn't\", 'being', 'if', 'here', 'at', 'under', 'who', 'y', 'these', 'does', 'won', \"you'll\", 'be', \"aren't\", 'she', 'which', 'up', \"doesn't\", 're', 'wouldn', 's', 'him', 'shouldn', 'why', 'shan', 'been', 'what', 'haven', 'ours', 'aren', 'can', 'should', 'about', \"it's\", 'its', 'there', 'me', 'their', 'same', 'most', 'did', 'in', 'your', 'doing', 'the', \"wouldn't\", \"mightn't\", 'is', 'other', \"should've\", 'or', 'ain', \"you've\", 'during', 'yours', 'hers', 'do', 'couldn', 't', 'were', 'such', \"couldn't\", 'his', 'before', 'wasn', 'so', 'itself', \"shan't\", 'needn', 'because', 'd', 'has', \"won't\", 'we', 'have', 'after', 'all', 'from', 'myself', 'only', 'above', \"shouldn't\", \"didn't\", 'are', 'but', 'than', \"mustn't\", 'this', 'between', 'they', 'was', 'having', 'themselves'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['tokenized_text']=total_data['full_text'].apply(gensim.utils.simple_preprocess)"
      ],
      "metadata": {
        "id": "tqtGCr1YKwBn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B1S2u4JdLWmO",
        "outputId": "d2a47a4d-4289-497c-a8a8-efca0f94a769"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c22ab5b8-d1d4-4a12-ad53-daf7f6495ac7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>Target</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Israel starts the new year by demolishing a Pa...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[israel, starts, the, new, year, by, demolishi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@realDonaldTrump Trump the White Supremacist...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[realdonaldtrump, trump, the, white, supremaci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please read this. International blackmail from...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[please, read, this, international, blackmail,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Netanyahu accidentally calls Israel a 'nuclear...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[netanyahu, accidentally, calls, israel, nucle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jews werent getting their asses kicked on the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[jews, weren, getting, their, asses, kicked, o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c22ab5b8-d1d4-4a12-ad53-daf7f6495ac7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c22ab5b8-d1d4-4a12-ad53-daf7f6495ac7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c22ab5b8-d1d4-4a12-ad53-daf7f6495ac7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           full_text  Target  \\\n",
              "0  Israel starts the new year by demolishing a Pa...     0.0   \n",
              "1  @realDonaldTrump Trump the White Supremacist...     0.0   \n",
              "2  Please read this. International blackmail from...     1.0   \n",
              "3  Netanyahu accidentally calls Israel a 'nuclear...     0.0   \n",
              "4  Jews werent getting their asses kicked on the...     0.0   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [israel, starts, the, new, year, by, demolishi...  \n",
              "1  [realdonaldtrump, trump, the, white, supremaci...  \n",
              "2  [please, read, this, international, blackmail,...  \n",
              "3  [netanyahu, accidentally, calls, israel, nucle...  \n",
              "4  [jews, weren, getting, their, asses, kicked, o...  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(s):\n",
        "    cleantext=[]\n",
        "    for i in range(len(s)): \n",
        "        if(s[i] not in stop_words):\n",
        "                cleantext.append(s[i])\n",
        "    return cleantext"
      ],
      "metadata": {
        "id": "sTBUVgiwLYuw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['clean_tok_text']=total_data['tokenized_text'].apply(lambda x:remove_stopwords(x))\n",
        "total_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "pkW-6IXKLbsW",
        "outputId": "3082684f-fd1d-45f7-9e5d-2a4b6a21477c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be83f450-e717-4ec3-83c7-c8d8ee5adbd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>Target</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>clean_tok_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Israel starts the new year by demolishing a Pa...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[israel, starts, the, new, year, by, demolishi...</td>\n",
              "      <td>[israel, starts, new, year, demolishing, pales...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@realDonaldTrump Trump the White Supremacist...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[realdonaldtrump, trump, the, white, supremaci...</td>\n",
              "      <td>[realdonaldtrump, trump, white, supremacist, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please read this. International blackmail from...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[please, read, this, international, blackmail,...</td>\n",
              "      <td>[please, read, international, blackmail, ziona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Netanyahu accidentally calls Israel a 'nuclear...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[netanyahu, accidentally, calls, israel, nucle...</td>\n",
              "      <td>[netanyahu, accidentally, calls, israel, nucle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jews werent getting their asses kicked on the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[jews, weren, getting, their, asses, kicked, o...</td>\n",
              "      <td>[jews, getting, asses, kicked, streets, nyc, r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be83f450-e717-4ec3-83c7-c8d8ee5adbd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be83f450-e717-4ec3-83c7-c8d8ee5adbd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be83f450-e717-4ec3-83c7-c8d8ee5adbd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           full_text  Target  \\\n",
              "0  Israel starts the new year by demolishing a Pa...     0.0   \n",
              "1  @realDonaldTrump Trump the White Supremacist...     0.0   \n",
              "2  Please read this. International blackmail from...     1.0   \n",
              "3  Netanyahu accidentally calls Israel a 'nuclear...     0.0   \n",
              "4  Jews werent getting their asses kicked on the...     0.0   \n",
              "\n",
              "                                      tokenized_text  \\\n",
              "0  [israel, starts, the, new, year, by, demolishi...   \n",
              "1  [realdonaldtrump, trump, the, white, supremaci...   \n",
              "2  [please, read, this, international, blackmail,...   \n",
              "3  [netanyahu, accidentally, calls, israel, nucle...   \n",
              "4  [jews, weren, getting, their, asses, kicked, o...   \n",
              "\n",
              "                                      clean_tok_text  \n",
              "0  [israel, starts, new, year, demolishing, pales...  \n",
              "1  [realdonaldtrump, trump, white, supremacist, s...  \n",
              "2  [please, read, international, blackmail, ziona...  \n",
              "3  [netanyahu, accidentally, calls, israel, nucle...  \n",
              "4  [jews, getting, asses, kicked, streets, nyc, r...  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['clean_text'] = total_data['clean_tok_text'].apply(lambda x:' '.join(x))\n",
        "total_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "limCJf2aPe4y",
        "outputId": "2a6d65e0-832f-4161-d812-9f251a6f8bf6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d18f6e8-d3d4-47da-8906-24de5ee6d442\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>Target</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>clean_tok_text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Israel starts the new year by demolishing a Pa...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[israel, starts, the, new, year, by, demolishi...</td>\n",
              "      <td>[israel, starts, new, year, demolishing, pales...</td>\n",
              "      <td>israel starts new year demolishing palestinian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@realDonaldTrump Trump the White Supremacist...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[realdonaldtrump, trump, the, white, supremaci...</td>\n",
              "      <td>[realdonaldtrump, trump, white, supremacist, s...</td>\n",
              "      <td>realdonaldtrump trump white supremacist st gol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please read this. International blackmail from...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[please, read, this, international, blackmail,...</td>\n",
              "      <td>[please, read, international, blackmail, ziona...</td>\n",
              "      <td>please read international blackmail zionazis a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Netanyahu accidentally calls Israel a 'nuclear...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[netanyahu, accidentally, calls, israel, nucle...</td>\n",
              "      <td>[netanyahu, accidentally, calls, israel, nucle...</td>\n",
              "      <td>netanyahu accidentally calls israel nuclear po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jews werent getting their asses kicked on the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[jews, weren, getting, their, asses, kicked, o...</td>\n",
              "      <td>[jews, getting, asses, kicked, streets, nyc, r...</td>\n",
              "      <td>jews getting asses kicked streets nyc rudygiul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>@DanielHarris he saved more black peoples than...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[danielharris, he, saved, more, black, peoples...</td>\n",
              "      <td>[danielharris, saved, black, peoples, daniel, ...</td>\n",
              "      <td>danielharris saved black peoples daniel shut f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>@PhillyPugilist @DeSeanJackson10 nothing, if y...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[phillypugilist, deseanjackson, nothing, if, y...</td>\n",
              "      <td>[phillypugilist, deseanjackson, nothing, kkk, ...</td>\n",
              "      <td>phillypugilist deseanjackson nothing kkk white...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4017</th>\n",
              "      <td>The Nazis murdered millions of Jews because th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[the, nazis, murdered, millions, of, jews, bec...</td>\n",
              "      <td>[nazis, murdered, millions, jews, unwanted, mu...</td>\n",
              "      <td>nazis murdered millions jews unwanted murder m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4018</th>\n",
              "      <td>Meanwhile, a group of Orthodox Jews just had t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[meanwhile, group, of, orthodox, jews, just, h...</td>\n",
              "      <td>[meanwhile, group, orthodox, jews, cut, lock, ...</td>\n",
              "      <td>meanwhile group orthodox jews cut lock park city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>Ben Wheeler @E_Superdoom_Esq, a member of the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ben, wheeler, e_superdoom_esq, member, of, th...</td>\n",
              "      <td>[ben, wheeler, e_superdoom_esq, member, rail, ...</td>\n",
              "      <td>ben wheeler e_superdoom_esq member rail union ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4020 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d18f6e8-d3d4-47da-8906-24de5ee6d442')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d18f6e8-d3d4-47da-8906-24de5ee6d442 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d18f6e8-d3d4-47da-8906-24de5ee6d442');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              full_text  Target  \\\n",
              "0     Israel starts the new year by demolishing a Pa...     0.0   \n",
              "1     @realDonaldTrump Trump the White Supremacist...     0.0   \n",
              "2     Please read this. International blackmail from...     1.0   \n",
              "3     Netanyahu accidentally calls Israel a 'nuclear...     0.0   \n",
              "4     Jews werent getting their asses kicked on the...     0.0   \n",
              "...                                                 ...     ...   \n",
              "4015  @DanielHarris he saved more black peoples than...     NaN   \n",
              "4016  @PhillyPugilist @DeSeanJackson10 nothing, if y...     NaN   \n",
              "4017  The Nazis murdered millions of Jews because th...     NaN   \n",
              "4018  Meanwhile, a group of Orthodox Jews just had t...     NaN   \n",
              "4019  Ben Wheeler @E_Superdoom_Esq, a member of the ...     NaN   \n",
              "\n",
              "                                         tokenized_text  \\\n",
              "0     [israel, starts, the, new, year, by, demolishi...   \n",
              "1     [realdonaldtrump, trump, the, white, supremaci...   \n",
              "2     [please, read, this, international, blackmail,...   \n",
              "3     [netanyahu, accidentally, calls, israel, nucle...   \n",
              "4     [jews, weren, getting, their, asses, kicked, o...   \n",
              "...                                                 ...   \n",
              "4015  [danielharris, he, saved, more, black, peoples...   \n",
              "4016  [phillypugilist, deseanjackson, nothing, if, y...   \n",
              "4017  [the, nazis, murdered, millions, of, jews, bec...   \n",
              "4018  [meanwhile, group, of, orthodox, jews, just, h...   \n",
              "4019  [ben, wheeler, e_superdoom_esq, member, of, th...   \n",
              "\n",
              "                                         clean_tok_text  \\\n",
              "0     [israel, starts, new, year, demolishing, pales...   \n",
              "1     [realdonaldtrump, trump, white, supremacist, s...   \n",
              "2     [please, read, international, blackmail, ziona...   \n",
              "3     [netanyahu, accidentally, calls, israel, nucle...   \n",
              "4     [jews, getting, asses, kicked, streets, nyc, r...   \n",
              "...                                                 ...   \n",
              "4015  [danielharris, saved, black, peoples, daniel, ...   \n",
              "4016  [phillypugilist, deseanjackson, nothing, kkk, ...   \n",
              "4017  [nazis, murdered, millions, jews, unwanted, mu...   \n",
              "4018  [meanwhile, group, orthodox, jews, cut, lock, ...   \n",
              "4019  [ben, wheeler, e_superdoom_esq, member, rail, ...   \n",
              "\n",
              "                                             clean_text  \n",
              "0     israel starts new year demolishing palestinian...  \n",
              "1     realdonaldtrump trump white supremacist st gol...  \n",
              "2     please read international blackmail zionazis a...  \n",
              "3     netanyahu accidentally calls israel nuclear po...  \n",
              "4     jews getting asses kicked streets nyc rudygiul...  \n",
              "...                                                 ...  \n",
              "4015  danielharris saved black peoples daniel shut f...  \n",
              "4016  phillypugilist deseanjackson nothing kkk white...  \n",
              "4017  nazis murdered millions jews unwanted murder m...  \n",
              "4018   meanwhile group orthodox jews cut lock park city  \n",
              "4019  ben wheeler e_superdoom_esq member rail union ...  \n",
              "\n",
              "[4020 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from transformers import TFBertModel\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "fGp--DcBOvwu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in total_data['clean_text'].values:\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "    \n",
        "max_len=np.max(token_lens)"
      ],
      "metadata": {
        "id": "eE0ZQIujQFGQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSFgOEoeQPy_",
        "outputId": "5c5c44b3-9531-44ae-d03a-f90884ea6fef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX TOKENIZED SENTENCE LENGTH: 221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for i,txt in enumerate(total_data['clean_text'].values):\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "    if len(tokens)>80:\n",
        "        print(f\"INDEX: {i}, TEXT: {txt}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3HB-HLyQTcs",
        "outputId": "dc530629-3e08-41c4-8b2a-0ef0eafce584"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INDEX: 1898, TEXT: leylakhalid simonvrouwe judgefudge yb oo roni alonma ladyalmagreen joseetje resistdwp phant hebmacman thezionist mistertwyst frontline yes_we_cat themoiety scripteladora david_starof malkaavram boomtown go greatest scot israel danielmazahreh iluvdemocracy jhorn slax baroniesisters sweposten serhumanomiguel swisstechie yankees_rule_ pakeha amoyal priestsanity telavivbroker canpassforsmart dorrit_r rse aron_alee hillshaveeyes searchfeast erezneumark abushlomo breginleif toprantking pohonyangdamai grattan_h charlieluchian rasputinish narrow_p yes arent jew bible jews exist anymore nthere millions fakejews heritage hunters na bible jews nb holocaust nhttps co clducbcump\n",
            "INDEX: 1908, TEXT: skipaipac mikebloomberg jews jvplive jvpliveny jvpboston jvpbayarea chicagojvp nyujvp jvp_la jvpcolorado jvpgwu jvpindiana jvpmke jvpnola jvpseattle jvpsandiego jvptucson jvptwincities jvpvassar jvpvile ifnotnoworg ifnotnowboston ifnotnow_bayc https co aiqvhyo tx\n",
            "INDEX: 1935, TEXT: brasasen openeysdown steven talal toprantking no_israel_state mamash_lo leylakhalid makjob kimbennylarsen beerbaron seguelsaul passtheduchi joseetje pohonyangdamai mrpeabody david_starof shez eliavabey mlirh scripteladora m_jew thezionist ladyalmagreen nigib iluvdemocracy drawniv lehired hebmacman albertgooner dlsmith boomerangtime enlieretzaheret priestsanity yourfriendzippy mabigbelio aaisrael boomtown qtr_uk amilitantagnost stolimark fruitbatoo rururola slax coaxialcreature davidsy glennnross ilanyvv shoozer scopevale apartheidisrael racist nation planet know black jews actually treated appalling way check david sheen done lot work exposing https co fkw\n",
            "INDEX: 3028, TEXT: julianroepcke lovely zionazi djihad julian also work syria golan israel netanyahu apartheidregime bds whitehelmets jap freeassangenow bild tagesschau kenfm teamkenfm nachdenkseiten nuoviso spiegelanti telepolis_news rtdeutsch de_sputnik euronewsde https co vlzsqcwlal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['token_lens'] = token_lens"
      ],
      "metadata": {
        "id": "RzBrGcf6QYbf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dISiNyfuQnPl",
        "outputId": "1d8de5f9-0a8e-4511-b754-a38448f3f2ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4020, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['Target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Ym3DpfQqnq",
        "outputId": "7fdc12b6-c066-4ff2-ff52-dcaede84e3cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    2473\n",
              "1.0     743\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.loc[total_data.Target == 1.0, 'DataType'] = \"Train\"\n",
        "total_data.loc[total_data.Target == 0.0, 'DataType'] = \"Train\"\n",
        "total_data['DataType'] = total_data['DataType'].replace(np.nan, \"Test\")\n"
      ],
      "metadata": {
        "id": "p3z04yHiRFez"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = total_data[total_data['DataType']== \"Train\"]\n",
        "test_data = total_data[total_data['DataType']== \"Test\"]\n",
        "train_data['Target'] = train_data['Target'].astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv4Ucx8qUVkT",
        "outputId": "41fcc4b3-963a-46ac-e01d-dcc2c43991dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.Target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKL8UISLSU8D",
        "outputId": "289d0077-1bb9-49c1-97ec-0a0c6013fd86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.Target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsIkjACdSa6p",
        "outputId": "5e2ff797-15ef-4428-c6f5-4086bcf11a5e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data['clean_text'].values\n",
        "y = train_data['Target'].values"
      ],
      "metadata": {
        "id": "zTopPl5kS9em"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.2, stratify=y_valid, random_state=42)"
      ],
      "metadata": {
        "id": "gCdw57M1UqhZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_le = y_train.copy()\n",
        "y_valid_le = y_valid.copy()\n",
        "y_test_le = y_test.copy()"
      ],
      "metadata": {
        "id": "PIyW2eEyVWVS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "ohe = preprocessing.OneHotEncoder()\n",
        "y_train = ohe.fit_transform(np.array(y_train).reshape(-1, 1)).toarray()\n",
        "y_valid = ohe.fit_transform(np.array(y_valid).reshape(-1, 1)).toarray()\n",
        "y_test = ohe.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "5H8N9ct4Vdxy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TRAINING DATA: {X_train.shape[0]}\\nVALIDATION DATA: {X_valid.shape[0]}\\nTESTING DATA: {X_test.shape[0]}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd0AjMp2VfMn",
        "outputId": "aafc60fb-b6f0-4bff-b9fe-64089e9b1052"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA: 2572\n",
            "VALIDATION DATA: 515\n",
            "TESTING DATA: 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=256"
      ],
      "metadata": {
        "id": "VDsrh0wbVry8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data,max_len=MAX_LEN) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(np.array(encoded['input_ids']))\n",
        "        attention_masks.append(np.array(encoded['attention_mask']))\n",
        "    return np.array(input_ids),np.array(attention_masks)"
      ],
      "metadata": {
        "id": "SetIVw5qV9Dc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = tokenize(X_train, MAX_LEN)\n",
        "val_input_ids, val_attention_masks = tokenize(X_valid, MAX_LEN)\n",
        "test_input_ids, test_attention_masks = tokenize(X_test, MAX_LEN)"
      ],
      "metadata": {
        "id": "irH4lY4GV-KU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI35fekJV_Zg",
        "outputId": "ed815ab3-d697-4533-83ab-732bedee2a71"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(bert_model, max_len=MAX_LEN):\n",
        "    \n",
        "    ##params###\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    \n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    \n",
        "    embeddings = bert_model([input_ids,attention_masks])[1]\n",
        "    \n",
        "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(embeddings)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
        "    \n",
        "    model.compile(opt, loss=loss, metrics=accuracy)\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "6fGetRCOWBFK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(bert_model, MAX_LEN)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZxAtjaMWJP1",
        "outputId": "8edd9984-3379-4c7c-c244-2e6acf4f15e3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            1538        ['tf_bert_model[0][1]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids = np.stack(train_input_ids,axis =0)\n",
        "train_attention_masks = np.stack(train_attention_masks, axis = 0)"
      ],
      "metadata": {
        "id": "sPdOnpYlalpS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_bert = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkHtJ_PzWK9b",
        "outputId": "3e56995a-2cf1-4feb-c5a9-347d94830391"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "81/81 [==============================] - 148s 2s/step - loss: 0.4606 - categorical_accuracy: 0.7994 - val_loss: 0.3385 - val_categorical_accuracy: 0.8718\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 133s 2s/step - loss: 0.3189 - categorical_accuracy: 0.8806 - val_loss: 0.2980 - val_categorical_accuracy: 0.8951\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 135s 2s/step - loss: 0.2376 - categorical_accuracy: 0.9129 - val_loss: 0.3743 - val_categorical_accuracy: 0.8485\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.1825 - categorical_accuracy: 0.9347 - val_loss: 0.3266 - val_categorical_accuracy: 0.8738\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.1376 - categorical_accuracy: 0.9514 - val_loss: 0.3575 - val_categorical_accuracy: 0.8816\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.0725 - categorical_accuracy: 0.9751 - val_loss: 0.4114 - val_categorical_accuracy: 0.8854\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.0335 - categorical_accuracy: 0.9918 - val_loss: 0.5246 - val_categorical_accuracy: 0.8485\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.0246 - categorical_accuracy: 0.9938 - val_loss: 0.5431 - val_categorical_accuracy: 0.8777\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.0276 - categorical_accuracy: 0.9911 - val_loss: 0.5589 - val_categorical_accuracy: 0.8466\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 136s 2s/step - loss: 0.0169 - categorical_accuracy: 0.9946 - val_loss: 0.6369 - val_categorical_accuracy: 0.8505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert = model.predict([test_input_ids,test_attention_masks])"
      ],
      "metadata": {
        "id": "dUp5Wbf7aCj-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bert =  np.zeros_like(result_bert)\n",
        "y_pred_bert[np.arange(len(y_pred_bert)), result_bert.argmax(1)] = 1"
      ],
      "metadata": {
        "id": "O3LnBohJdu4I"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test.argmax(1), y_pred_bert.argmax(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhu9dxcKdwXw",
        "outputId": "c86ba9ea-c3e7-4c0c-ab8d-af81b5c10dee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[88, 11],\n",
              "       [ 8, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating outputs"
      ],
      "metadata": {
        "id": "-hzqB6Cxeg2k"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert = model.predict([test_input_ids,test_attention_masks])"
      ],
      "metadata": {
        "id": "Vrj2eFEseRXZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_data['clean_text']"
      ],
      "metadata": {
        "id": "MiN2ygAyO4IR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCQv3HDAO93b",
        "outputId": "2749f095-ce85-4a8d-c1cf-8f5087d81b84"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3216    israel health minister claims coronavirus divi...\n",
              "3217    greysfaer mean yelling hail victory fuming kik...\n",
              "3218           https co bnwyz dtkr israel involv one care\n",
              "3219    dear jews hindus fiercest allies need educate ...\n",
              "3220    carrieksada baalter updated include hate gener...\n",
              "                              ...                        \n",
              "4015    danielharris saved black peoples daniel shut f...\n",
              "4016    phillypugilist deseanjackson nothing kkk white...\n",
              "4017    nazis murdered millions jews unwanted murder m...\n",
              "4018     meanwhile group orthodox jews cut lock park city\n",
              "4019    ben wheeler e_superdoom_esq member rail union ...\n",
              "Name: clean_text, Length: 804, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_ids, test_attention_masks = tokenize(np.array(X_test), MAX_LEN)"
      ],
      "metadata": {
        "id": "jn_ZCxXROjEH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert = model.predict([test_input_ids,test_attention_masks])"
      ],
      "metadata": {
        "id": "c-Q_ihLxO2ZB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bert =  np.zeros_like(result_bert)\n",
        "y_pred_bert[np.arange(len(y_pred_bert)), result_bert.argmax(1)] = 1"
      ],
      "metadata": {
        "id": "90T1ayo9PFpG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Target'] = y_pred_bert.argmax(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vf5Ei3NPK0b",
        "outputId": "23823a1d-4dc7-4550-edf3-c7ce45c41ec1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Target'].to_csv(filePath+'predicted.csv')"
      ],
      "metadata": {
        "id": "D8tC4kflPNKs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z8eqvbe7PTvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}